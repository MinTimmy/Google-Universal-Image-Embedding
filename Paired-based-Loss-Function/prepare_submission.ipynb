{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPp9RwdoLBhlZmMNWhpgJB/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"b716e3c59e9f498a9e5b778d8cc5ac8a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b6159760b56d409d9c35647a0cbd8dc4","IPY_MODEL_ad6b0ff1b141458a82bf615714622dd5","IPY_MODEL_25fa645a717147a2bde6dbba6cecdb37"],"layout":"IPY_MODEL_cc83d3bf7fe54122b3bfb278f564ef7b"}},"b6159760b56d409d9c35647a0cbd8dc4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a06a0891df74ebd848b47b9b8742554","placeholder":"​","style":"IPY_MODEL_2a82359d2ff2485d80cbb14369c6522b","value":"100%"}},"ad6b0ff1b141458a82bf615714622dd5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fafec58df0b426e8a58824e509cd44b","max":102540417,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64a7272e7e7948bbbc2ab25862038377","value":102540417}},"25fa645a717147a2bde6dbba6cecdb37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5d877ea9fd24852931d4b896ff0ffc5","placeholder":"​","style":"IPY_MODEL_9993bc48bb704cef9dc830984361342f","value":" 97.8M/97.8M [00:00&lt;00:00, 129MB/s]"}},"cc83d3bf7fe54122b3bfb278f564ef7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a06a0891df74ebd848b47b9b8742554":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a82359d2ff2485d80cbb14369c6522b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2fafec58df0b426e8a58824e509cd44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64a7272e7e7948bbbc2ab25862038377":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5d877ea9fd24852931d4b896ff0ffc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9993bc48bb704cef9dc830984361342f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0kRDw1QI5RT8","executionInfo":{"status":"ok","timestamp":1662444348185,"user_tz":-480,"elapsed":21795,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}},"outputId":"26f30fd3-b065-4c79-aad7-474f35865d83"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Master/Kaggle/Code/Integrating_Language_Guidance_into_Vision-based_Deep_Metric_Learning/demo4"],"metadata":{"id":"o3V8jOea6PSc","executionInfo":{"status":"ok","timestamp":1662444349330,"user_tz":-480,"elapsed":1153,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"429c69e1-901c-476f-9a0b-287938c568d2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Master/Kaggle/Code/Integrating_Language_Guidance_into_Vision-based_Deep_Metric_Learning/demo4\n"]}]},{"cell_type":"markdown","source":["# import"],"metadata":{"id":"bVrXjVpyULKX"}},{"cell_type":"code","source":["import argparse\n","import collections\n","import contextlib\n","import copy\n","import json\n","import os\n","import random\n","import sys\n","import time\n","import warnings\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","import matplotlib\n","\n","matplotlib.use('agg')\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle as pkl\n","import termcolor\n","from tqdm import tqdm\n","\n","import parameters as par\n","import utilities.misc as misc"],"metadata":{"id":"UfOuDNS6n4Kb","executionInfo":{"status":"ok","timestamp":1662444354960,"user_tz":-480,"elapsed":5634,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch, torch.nn as nn, torch.nn.functional as F\n","import torch.multiprocessing\n","import torchvision\n","\n","torch.multiprocessing.set_sharing_strategy('file_system')"],"metadata":{"id":"38UrpHejnJ27","executionInfo":{"status":"ok","timestamp":1662444355378,"user_tz":-480,"elapsed":437,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# ResNet"],"metadata":{"id":"2LJ-AETsoWwF"}},{"cell_type":"code","source":["from torchvision.models import resnet50, ResNet50_Weights\n","\n","class Network(torch.nn.Module):\n","# class Network(torch.jit.ScriptModule):\n","    def __init__(self, opt):\n","        super(Network, self).__init__()\n","\n","        self.pars = opt\n","        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n","        self.name = opt.arch\n","        \n","        opt.penultimate_dim = self.model.fc.in_features\n","\n","        self.model.fc = torch.nn.Linear(\n","            self.model.fc.in_features, opt.embed_dim)\n","\n","        self.layer_blocks = nn.ModuleList([\n","            self.model.layer1, self.model.layer2, self.model.layer3,\n","            self.model.layer4\n","        ])\n","\n","        self.pool_base = torch.nn.AdaptiveAvgPool2d(1)\n","        # self.pool_aux = torch.nn.AdaptiveMaxPool2d(\n","        #     1) if 'double' in opt.arch else None\n","\n","    # def forward(self, x, warmup=False, **kwargs):\n","    def forward(self, x):\n","        x = torchvision.transforms.functional.resize(x,size=[300, 300])\n","        x = x / 255.0\n","        x = torchvision.transforms.functional.normalize(x, \n","                                            mean=[0.485, 0.456, 0.406], \n","                                            std=[0.229, 0.224, 0.225])\n","        context = torch.no_grad()\n","        with context:\n","            x = self.model.maxpool(\n","                self.model.relu(self.model.bn1(self.model.conv1(x))))\n","            for i, layerblock in enumerate(self.layer_blocks):\n","                x = layerblock(x)\n","            y = self.pool_base(x)\n","            y = y.view(y.size(0), -1)\n","\n","        z = self.model.fc(y)\n","\n","        # if 'normalize' in self.pars.arch:\n","        z = torch.nn.functional.normalize(z, dim=-1)\n","        return z\n","        # return {\n","        #     'embeds': z,\n","        #     'avg_features': y,\n","        #     'features': x,\n","        #     'extra_embeds': prepool_y\n","        # }\n"],"metadata":{"id":"6oLqPMo6f7yB","executionInfo":{"status":"ok","timestamp":1662444355379,"user_tz":-480,"elapsed":5,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Make Submission File"],"metadata":{"id":"_W2uB_DmTGxH"}},{"cell_type":"code","source":["output = torch.load(\n","    '/content/drive/MyDrive/Master/Kaggle/Code/Integrating_Language_Guidance_into_Vision-based_Deep_Metric_Learning/demo4/Training_Results/guie_CLIP_TensorFlow_train_example/multisimilarity_small_no_pesudolables_1/checkpoint_Val_embeds_e_recall@1_multisimilarity.pth.tar',\n","    map_location = torch.device('cpu'),\n","    )\n","\n","print(output.keys())\n","opt = output['opt']"],"metadata":{"id":"803KyPXNjaF6","executionInfo":{"status":"ok","timestamp":1662444363464,"user_tz":-480,"elapsed":8090,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d2b98c03-696d-4434-f3da-aac6d2bb87cc"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['state_dict', 'opt'])\n"]}]},{"cell_type":"code","source":["opt.device = torch.device('cpu')\n","# opt.device = torch.device('cuda')\n","model = Network(opt)"],"metadata":{"id":"4SueMLSRkyUr","executionInfo":{"status":"ok","timestamp":1662444365125,"user_tz":-480,"elapsed":1667,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["b716e3c59e9f498a9e5b778d8cc5ac8a","b6159760b56d409d9c35647a0cbd8dc4","ad6b0ff1b141458a82bf615714622dd5","25fa645a717147a2bde6dbba6cecdb37","cc83d3bf7fe54122b3bfb278f564ef7b","3a06a0891df74ebd848b47b9b8742554","2a82359d2ff2485d80cbb14369c6522b","2fafec58df0b426e8a58824e509cd44b","64a7272e7e7948bbbc2ab25862038377","d5d877ea9fd24852931d4b896ff0ffc5","9993bc48bb704cef9dc830984361342f"]},"outputId":"d8b3bf65-efda-4124-edad-7af7ed9f678d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/97.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b716e3c59e9f498a9e5b778d8cc5ac8a"}},"metadata":{}}]},{"cell_type":"code","source":["from torchsummary import summary\n","summary(model, (3 , 300, 300))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gTm4STnpkykC","executionInfo":{"status":"ok","timestamp":1662444366517,"user_tz":-480,"elapsed":1400,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}},"outputId":"0c6db00b-23ff-491b-ecc1-f03a62c83c6e"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 150, 150]           9,408\n","       BatchNorm2d-2         [-1, 64, 150, 150]             128\n","              ReLU-3         [-1, 64, 150, 150]               0\n","         MaxPool2d-4           [-1, 64, 75, 75]               0\n","            Conv2d-5           [-1, 64, 75, 75]           4,096\n","            Conv2d-6           [-1, 64, 75, 75]           4,096\n","       BatchNorm2d-7           [-1, 64, 75, 75]             128\n","       BatchNorm2d-8           [-1, 64, 75, 75]             128\n","              ReLU-9           [-1, 64, 75, 75]               0\n","             ReLU-10           [-1, 64, 75, 75]               0\n","           Conv2d-11           [-1, 64, 75, 75]          36,864\n","           Conv2d-12           [-1, 64, 75, 75]          36,864\n","      BatchNorm2d-13           [-1, 64, 75, 75]             128\n","      BatchNorm2d-14           [-1, 64, 75, 75]             128\n","             ReLU-15           [-1, 64, 75, 75]               0\n","             ReLU-16           [-1, 64, 75, 75]               0\n","           Conv2d-17          [-1, 256, 75, 75]          16,384\n","           Conv2d-18          [-1, 256, 75, 75]          16,384\n","      BatchNorm2d-19          [-1, 256, 75, 75]             512\n","      BatchNorm2d-20          [-1, 256, 75, 75]             512\n","           Conv2d-21          [-1, 256, 75, 75]          16,384\n","           Conv2d-22          [-1, 256, 75, 75]          16,384\n","      BatchNorm2d-23          [-1, 256, 75, 75]             512\n","      BatchNorm2d-24          [-1, 256, 75, 75]             512\n","             ReLU-25          [-1, 256, 75, 75]               0\n","             ReLU-26          [-1, 256, 75, 75]               0\n","       Bottleneck-27          [-1, 256, 75, 75]               0\n","       Bottleneck-28          [-1, 256, 75, 75]               0\n","           Conv2d-29           [-1, 64, 75, 75]          16,384\n","           Conv2d-30           [-1, 64, 75, 75]          16,384\n","      BatchNorm2d-31           [-1, 64, 75, 75]             128\n","      BatchNorm2d-32           [-1, 64, 75, 75]             128\n","             ReLU-33           [-1, 64, 75, 75]               0\n","             ReLU-34           [-1, 64, 75, 75]               0\n","           Conv2d-35           [-1, 64, 75, 75]          36,864\n","           Conv2d-36           [-1, 64, 75, 75]          36,864\n","      BatchNorm2d-37           [-1, 64, 75, 75]             128\n","      BatchNorm2d-38           [-1, 64, 75, 75]             128\n","             ReLU-39           [-1, 64, 75, 75]               0\n","             ReLU-40           [-1, 64, 75, 75]               0\n","           Conv2d-41          [-1, 256, 75, 75]          16,384\n","           Conv2d-42          [-1, 256, 75, 75]          16,384\n","      BatchNorm2d-43          [-1, 256, 75, 75]             512\n","      BatchNorm2d-44          [-1, 256, 75, 75]             512\n","             ReLU-45          [-1, 256, 75, 75]               0\n","             ReLU-46          [-1, 256, 75, 75]               0\n","       Bottleneck-47          [-1, 256, 75, 75]               0\n","       Bottleneck-48          [-1, 256, 75, 75]               0\n","           Conv2d-49           [-1, 64, 75, 75]          16,384\n","           Conv2d-50           [-1, 64, 75, 75]          16,384\n","      BatchNorm2d-51           [-1, 64, 75, 75]             128\n","      BatchNorm2d-52           [-1, 64, 75, 75]             128\n","             ReLU-53           [-1, 64, 75, 75]               0\n","             ReLU-54           [-1, 64, 75, 75]               0\n","           Conv2d-55           [-1, 64, 75, 75]          36,864\n","           Conv2d-56           [-1, 64, 75, 75]          36,864\n","      BatchNorm2d-57           [-1, 64, 75, 75]             128\n","      BatchNorm2d-58           [-1, 64, 75, 75]             128\n","             ReLU-59           [-1, 64, 75, 75]               0\n","             ReLU-60           [-1, 64, 75, 75]               0\n","           Conv2d-61          [-1, 256, 75, 75]          16,384\n","           Conv2d-62          [-1, 256, 75, 75]          16,384\n","      BatchNorm2d-63          [-1, 256, 75, 75]             512\n","      BatchNorm2d-64          [-1, 256, 75, 75]             512\n","             ReLU-65          [-1, 256, 75, 75]               0\n","             ReLU-66          [-1, 256, 75, 75]               0\n","       Bottleneck-67          [-1, 256, 75, 75]               0\n","       Bottleneck-68          [-1, 256, 75, 75]               0\n","           Conv2d-69          [-1, 128, 75, 75]          32,768\n","           Conv2d-70          [-1, 128, 75, 75]          32,768\n","      BatchNorm2d-71          [-1, 128, 75, 75]             256\n","      BatchNorm2d-72          [-1, 128, 75, 75]             256\n","             ReLU-73          [-1, 128, 75, 75]               0\n","             ReLU-74          [-1, 128, 75, 75]               0\n","           Conv2d-75          [-1, 128, 38, 38]         147,456\n","           Conv2d-76          [-1, 128, 38, 38]         147,456\n","      BatchNorm2d-77          [-1, 128, 38, 38]             256\n","      BatchNorm2d-78          [-1, 128, 38, 38]             256\n","             ReLU-79          [-1, 128, 38, 38]               0\n","             ReLU-80          [-1, 128, 38, 38]               0\n","           Conv2d-81          [-1, 512, 38, 38]          65,536\n","           Conv2d-82          [-1, 512, 38, 38]          65,536\n","      BatchNorm2d-83          [-1, 512, 38, 38]           1,024\n","      BatchNorm2d-84          [-1, 512, 38, 38]           1,024\n","           Conv2d-85          [-1, 512, 38, 38]         131,072\n","           Conv2d-86          [-1, 512, 38, 38]         131,072\n","      BatchNorm2d-87          [-1, 512, 38, 38]           1,024\n","      BatchNorm2d-88          [-1, 512, 38, 38]           1,024\n","             ReLU-89          [-1, 512, 38, 38]               0\n","             ReLU-90          [-1, 512, 38, 38]               0\n","       Bottleneck-91          [-1, 512, 38, 38]               0\n","       Bottleneck-92          [-1, 512, 38, 38]               0\n","           Conv2d-93          [-1, 128, 38, 38]          65,536\n","           Conv2d-94          [-1, 128, 38, 38]          65,536\n","      BatchNorm2d-95          [-1, 128, 38, 38]             256\n","      BatchNorm2d-96          [-1, 128, 38, 38]             256\n","             ReLU-97          [-1, 128, 38, 38]               0\n","             ReLU-98          [-1, 128, 38, 38]               0\n","           Conv2d-99          [-1, 128, 38, 38]         147,456\n","          Conv2d-100          [-1, 128, 38, 38]         147,456\n","     BatchNorm2d-101          [-1, 128, 38, 38]             256\n","     BatchNorm2d-102          [-1, 128, 38, 38]             256\n","            ReLU-103          [-1, 128, 38, 38]               0\n","            ReLU-104          [-1, 128, 38, 38]               0\n","          Conv2d-105          [-1, 512, 38, 38]          65,536\n","          Conv2d-106          [-1, 512, 38, 38]          65,536\n","     BatchNorm2d-107          [-1, 512, 38, 38]           1,024\n","     BatchNorm2d-108          [-1, 512, 38, 38]           1,024\n","            ReLU-109          [-1, 512, 38, 38]               0\n","            ReLU-110          [-1, 512, 38, 38]               0\n","      Bottleneck-111          [-1, 512, 38, 38]               0\n","      Bottleneck-112          [-1, 512, 38, 38]               0\n","          Conv2d-113          [-1, 128, 38, 38]          65,536\n","          Conv2d-114          [-1, 128, 38, 38]          65,536\n","     BatchNorm2d-115          [-1, 128, 38, 38]             256\n","     BatchNorm2d-116          [-1, 128, 38, 38]             256\n","            ReLU-117          [-1, 128, 38, 38]               0\n","            ReLU-118          [-1, 128, 38, 38]               0\n","          Conv2d-119          [-1, 128, 38, 38]         147,456\n","          Conv2d-120          [-1, 128, 38, 38]         147,456\n","     BatchNorm2d-121          [-1, 128, 38, 38]             256\n","     BatchNorm2d-122          [-1, 128, 38, 38]             256\n","            ReLU-123          [-1, 128, 38, 38]               0\n","            ReLU-124          [-1, 128, 38, 38]               0\n","          Conv2d-125          [-1, 512, 38, 38]          65,536\n","          Conv2d-126          [-1, 512, 38, 38]          65,536\n","     BatchNorm2d-127          [-1, 512, 38, 38]           1,024\n","     BatchNorm2d-128          [-1, 512, 38, 38]           1,024\n","            ReLU-129          [-1, 512, 38, 38]               0\n","            ReLU-130          [-1, 512, 38, 38]               0\n","      Bottleneck-131          [-1, 512, 38, 38]               0\n","      Bottleneck-132          [-1, 512, 38, 38]               0\n","          Conv2d-133          [-1, 128, 38, 38]          65,536\n","          Conv2d-134          [-1, 128, 38, 38]          65,536\n","     BatchNorm2d-135          [-1, 128, 38, 38]             256\n","     BatchNorm2d-136          [-1, 128, 38, 38]             256\n","            ReLU-137          [-1, 128, 38, 38]               0\n","            ReLU-138          [-1, 128, 38, 38]               0\n","          Conv2d-139          [-1, 128, 38, 38]         147,456\n","          Conv2d-140          [-1, 128, 38, 38]         147,456\n","     BatchNorm2d-141          [-1, 128, 38, 38]             256\n","     BatchNorm2d-142          [-1, 128, 38, 38]             256\n","            ReLU-143          [-1, 128, 38, 38]               0\n","            ReLU-144          [-1, 128, 38, 38]               0\n","          Conv2d-145          [-1, 512, 38, 38]          65,536\n","          Conv2d-146          [-1, 512, 38, 38]          65,536\n","     BatchNorm2d-147          [-1, 512, 38, 38]           1,024\n","     BatchNorm2d-148          [-1, 512, 38, 38]           1,024\n","            ReLU-149          [-1, 512, 38, 38]               0\n","            ReLU-150          [-1, 512, 38, 38]               0\n","      Bottleneck-151          [-1, 512, 38, 38]               0\n","      Bottleneck-152          [-1, 512, 38, 38]               0\n","          Conv2d-153          [-1, 256, 38, 38]         131,072\n","          Conv2d-154          [-1, 256, 38, 38]         131,072\n","     BatchNorm2d-155          [-1, 256, 38, 38]             512\n","     BatchNorm2d-156          [-1, 256, 38, 38]             512\n","            ReLU-157          [-1, 256, 38, 38]               0\n","            ReLU-158          [-1, 256, 38, 38]               0\n","          Conv2d-159          [-1, 256, 19, 19]         589,824\n","          Conv2d-160          [-1, 256, 19, 19]         589,824\n","     BatchNorm2d-161          [-1, 256, 19, 19]             512\n","     BatchNorm2d-162          [-1, 256, 19, 19]             512\n","            ReLU-163          [-1, 256, 19, 19]               0\n","            ReLU-164          [-1, 256, 19, 19]               0\n","          Conv2d-165         [-1, 1024, 19, 19]         262,144\n","          Conv2d-166         [-1, 1024, 19, 19]         262,144\n","     BatchNorm2d-167         [-1, 1024, 19, 19]           2,048\n","     BatchNorm2d-168         [-1, 1024, 19, 19]           2,048\n","          Conv2d-169         [-1, 1024, 19, 19]         524,288\n","          Conv2d-170         [-1, 1024, 19, 19]         524,288\n","     BatchNorm2d-171         [-1, 1024, 19, 19]           2,048\n","     BatchNorm2d-172         [-1, 1024, 19, 19]           2,048\n","            ReLU-173         [-1, 1024, 19, 19]               0\n","            ReLU-174         [-1, 1024, 19, 19]               0\n","      Bottleneck-175         [-1, 1024, 19, 19]               0\n","      Bottleneck-176         [-1, 1024, 19, 19]               0\n","          Conv2d-177          [-1, 256, 19, 19]         262,144\n","          Conv2d-178          [-1, 256, 19, 19]         262,144\n","     BatchNorm2d-179          [-1, 256, 19, 19]             512\n","     BatchNorm2d-180          [-1, 256, 19, 19]             512\n","            ReLU-181          [-1, 256, 19, 19]               0\n","            ReLU-182          [-1, 256, 19, 19]               0\n","          Conv2d-183          [-1, 256, 19, 19]         589,824\n","          Conv2d-184          [-1, 256, 19, 19]         589,824\n","     BatchNorm2d-185          [-1, 256, 19, 19]             512\n","     BatchNorm2d-186          [-1, 256, 19, 19]             512\n","            ReLU-187          [-1, 256, 19, 19]               0\n","            ReLU-188          [-1, 256, 19, 19]               0\n","          Conv2d-189         [-1, 1024, 19, 19]         262,144\n","          Conv2d-190         [-1, 1024, 19, 19]         262,144\n","     BatchNorm2d-191         [-1, 1024, 19, 19]           2,048\n","     BatchNorm2d-192         [-1, 1024, 19, 19]           2,048\n","            ReLU-193         [-1, 1024, 19, 19]               0\n","            ReLU-194         [-1, 1024, 19, 19]               0\n","      Bottleneck-195         [-1, 1024, 19, 19]               0\n","      Bottleneck-196         [-1, 1024, 19, 19]               0\n","          Conv2d-197          [-1, 256, 19, 19]         262,144\n","          Conv2d-198          [-1, 256, 19, 19]         262,144\n","     BatchNorm2d-199          [-1, 256, 19, 19]             512\n","     BatchNorm2d-200          [-1, 256, 19, 19]             512\n","            ReLU-201          [-1, 256, 19, 19]               0\n","            ReLU-202          [-1, 256, 19, 19]               0\n","          Conv2d-203          [-1, 256, 19, 19]         589,824\n","          Conv2d-204          [-1, 256, 19, 19]         589,824\n","     BatchNorm2d-205          [-1, 256, 19, 19]             512\n","     BatchNorm2d-206          [-1, 256, 19, 19]             512\n","            ReLU-207          [-1, 256, 19, 19]               0\n","            ReLU-208          [-1, 256, 19, 19]               0\n","          Conv2d-209         [-1, 1024, 19, 19]         262,144\n","          Conv2d-210         [-1, 1024, 19, 19]         262,144\n","     BatchNorm2d-211         [-1, 1024, 19, 19]           2,048\n","     BatchNorm2d-212         [-1, 1024, 19, 19]           2,048\n","            ReLU-213         [-1, 1024, 19, 19]               0\n","            ReLU-214         [-1, 1024, 19, 19]               0\n","      Bottleneck-215         [-1, 1024, 19, 19]               0\n","      Bottleneck-216         [-1, 1024, 19, 19]               0\n","          Conv2d-217          [-1, 256, 19, 19]         262,144\n","          Conv2d-218          [-1, 256, 19, 19]         262,144\n","     BatchNorm2d-219          [-1, 256, 19, 19]             512\n","     BatchNorm2d-220          [-1, 256, 19, 19]             512\n","            ReLU-221          [-1, 256, 19, 19]               0\n","            ReLU-222          [-1, 256, 19, 19]               0\n","          Conv2d-223          [-1, 256, 19, 19]         589,824\n","          Conv2d-224          [-1, 256, 19, 19]         589,824\n","     BatchNorm2d-225          [-1, 256, 19, 19]             512\n","     BatchNorm2d-226          [-1, 256, 19, 19]             512\n","            ReLU-227          [-1, 256, 19, 19]               0\n","            ReLU-228          [-1, 256, 19, 19]               0\n","          Conv2d-229         [-1, 1024, 19, 19]         262,144\n","          Conv2d-230         [-1, 1024, 19, 19]         262,144\n","     BatchNorm2d-231         [-1, 1024, 19, 19]           2,048\n","     BatchNorm2d-232         [-1, 1024, 19, 19]           2,048\n","            ReLU-233         [-1, 1024, 19, 19]               0\n","            ReLU-234         [-1, 1024, 19, 19]               0\n","      Bottleneck-235         [-1, 1024, 19, 19]               0\n","      Bottleneck-236         [-1, 1024, 19, 19]               0\n","          Conv2d-237          [-1, 256, 19, 19]         262,144\n","          Conv2d-238          [-1, 256, 19, 19]         262,144\n","     BatchNorm2d-239          [-1, 256, 19, 19]             512\n","     BatchNorm2d-240          [-1, 256, 19, 19]             512\n","            ReLU-241          [-1, 256, 19, 19]               0\n","            ReLU-242          [-1, 256, 19, 19]               0\n","          Conv2d-243          [-1, 256, 19, 19]         589,824\n","          Conv2d-244          [-1, 256, 19, 19]         589,824\n","     BatchNorm2d-245          [-1, 256, 19, 19]             512\n","     BatchNorm2d-246          [-1, 256, 19, 19]             512\n","            ReLU-247          [-1, 256, 19, 19]               0\n","            ReLU-248          [-1, 256, 19, 19]               0\n","          Conv2d-249         [-1, 1024, 19, 19]         262,144\n","          Conv2d-250         [-1, 1024, 19, 19]         262,144\n","     BatchNorm2d-251         [-1, 1024, 19, 19]           2,048\n","     BatchNorm2d-252         [-1, 1024, 19, 19]           2,048\n","            ReLU-253         [-1, 1024, 19, 19]               0\n","            ReLU-254         [-1, 1024, 19, 19]               0\n","      Bottleneck-255         [-1, 1024, 19, 19]               0\n","      Bottleneck-256         [-1, 1024, 19, 19]               0\n","          Conv2d-257          [-1, 256, 19, 19]         262,144\n","          Conv2d-258          [-1, 256, 19, 19]         262,144\n","     BatchNorm2d-259          [-1, 256, 19, 19]             512\n","     BatchNorm2d-260          [-1, 256, 19, 19]             512\n","            ReLU-261          [-1, 256, 19, 19]               0\n","            ReLU-262          [-1, 256, 19, 19]               0\n","          Conv2d-263          [-1, 256, 19, 19]         589,824\n","          Conv2d-264          [-1, 256, 19, 19]         589,824\n","     BatchNorm2d-265          [-1, 256, 19, 19]             512\n","     BatchNorm2d-266          [-1, 256, 19, 19]             512\n","            ReLU-267          [-1, 256, 19, 19]               0\n","            ReLU-268          [-1, 256, 19, 19]               0\n","          Conv2d-269         [-1, 1024, 19, 19]         262,144\n","          Conv2d-270         [-1, 1024, 19, 19]         262,144\n","     BatchNorm2d-271         [-1, 1024, 19, 19]           2,048\n","     BatchNorm2d-272         [-1, 1024, 19, 19]           2,048\n","            ReLU-273         [-1, 1024, 19, 19]               0\n","            ReLU-274         [-1, 1024, 19, 19]               0\n","      Bottleneck-275         [-1, 1024, 19, 19]               0\n","      Bottleneck-276         [-1, 1024, 19, 19]               0\n","          Conv2d-277          [-1, 512, 19, 19]         524,288\n","          Conv2d-278          [-1, 512, 19, 19]         524,288\n","     BatchNorm2d-279          [-1, 512, 19, 19]           1,024\n","     BatchNorm2d-280          [-1, 512, 19, 19]           1,024\n","            ReLU-281          [-1, 512, 19, 19]               0\n","            ReLU-282          [-1, 512, 19, 19]               0\n","          Conv2d-283          [-1, 512, 10, 10]       2,359,296\n","          Conv2d-284          [-1, 512, 10, 10]       2,359,296\n","     BatchNorm2d-285          [-1, 512, 10, 10]           1,024\n","     BatchNorm2d-286          [-1, 512, 10, 10]           1,024\n","            ReLU-287          [-1, 512, 10, 10]               0\n","            ReLU-288          [-1, 512, 10, 10]               0\n","          Conv2d-289         [-1, 2048, 10, 10]       1,048,576\n","          Conv2d-290         [-1, 2048, 10, 10]       1,048,576\n","     BatchNorm2d-291         [-1, 2048, 10, 10]           4,096\n","     BatchNorm2d-292         [-1, 2048, 10, 10]           4,096\n","          Conv2d-293         [-1, 2048, 10, 10]       2,097,152\n","          Conv2d-294         [-1, 2048, 10, 10]       2,097,152\n","     BatchNorm2d-295         [-1, 2048, 10, 10]           4,096\n","     BatchNorm2d-296         [-1, 2048, 10, 10]           4,096\n","            ReLU-297         [-1, 2048, 10, 10]               0\n","            ReLU-298         [-1, 2048, 10, 10]               0\n","      Bottleneck-299         [-1, 2048, 10, 10]               0\n","      Bottleneck-300         [-1, 2048, 10, 10]               0\n","          Conv2d-301          [-1, 512, 10, 10]       1,048,576\n","          Conv2d-302          [-1, 512, 10, 10]       1,048,576\n","     BatchNorm2d-303          [-1, 512, 10, 10]           1,024\n","     BatchNorm2d-304          [-1, 512, 10, 10]           1,024\n","            ReLU-305          [-1, 512, 10, 10]               0\n","            ReLU-306          [-1, 512, 10, 10]               0\n","          Conv2d-307          [-1, 512, 10, 10]       2,359,296\n","          Conv2d-308          [-1, 512, 10, 10]       2,359,296\n","     BatchNorm2d-309          [-1, 512, 10, 10]           1,024\n","     BatchNorm2d-310          [-1, 512, 10, 10]           1,024\n","            ReLU-311          [-1, 512, 10, 10]               0\n","            ReLU-312          [-1, 512, 10, 10]               0\n","          Conv2d-313         [-1, 2048, 10, 10]       1,048,576\n","          Conv2d-314         [-1, 2048, 10, 10]       1,048,576\n","     BatchNorm2d-315         [-1, 2048, 10, 10]           4,096\n","     BatchNorm2d-316         [-1, 2048, 10, 10]           4,096\n","            ReLU-317         [-1, 2048, 10, 10]               0\n","            ReLU-318         [-1, 2048, 10, 10]               0\n","      Bottleneck-319         [-1, 2048, 10, 10]               0\n","      Bottleneck-320         [-1, 2048, 10, 10]               0\n","          Conv2d-321          [-1, 512, 10, 10]       1,048,576\n","          Conv2d-322          [-1, 512, 10, 10]       1,048,576\n","     BatchNorm2d-323          [-1, 512, 10, 10]           1,024\n","     BatchNorm2d-324          [-1, 512, 10, 10]           1,024\n","            ReLU-325          [-1, 512, 10, 10]               0\n","            ReLU-326          [-1, 512, 10, 10]               0\n","          Conv2d-327          [-1, 512, 10, 10]       2,359,296\n","          Conv2d-328          [-1, 512, 10, 10]       2,359,296\n","     BatchNorm2d-329          [-1, 512, 10, 10]           1,024\n","     BatchNorm2d-330          [-1, 512, 10, 10]           1,024\n","            ReLU-331          [-1, 512, 10, 10]               0\n","            ReLU-332          [-1, 512, 10, 10]               0\n","          Conv2d-333         [-1, 2048, 10, 10]       1,048,576\n","          Conv2d-334         [-1, 2048, 10, 10]       1,048,576\n","     BatchNorm2d-335         [-1, 2048, 10, 10]           4,096\n","     BatchNorm2d-336         [-1, 2048, 10, 10]           4,096\n","            ReLU-337         [-1, 2048, 10, 10]               0\n","            ReLU-338         [-1, 2048, 10, 10]               0\n","      Bottleneck-339         [-1, 2048, 10, 10]               0\n","      Bottleneck-340         [-1, 2048, 10, 10]               0\n","AdaptiveAvgPool2d-341           [-1, 2048, 1, 1]               0\n","          Linear-342                   [-1, 64]         131,136\n","================================================================\n","Total params: 47,137,664\n","Trainable params: 47,137,664\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.03\n","Forward/backward pass size (MB): 1011.51\n","Params size (MB): 179.82\n","Estimated Total Size (MB): 1192.35\n","----------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# from torchsummary import summary\n","# summary(model, (3 , 300, 300))"],"metadata":{"id":"mU-PTuuRoeSf","executionInfo":{"status":"ok","timestamp":1662444366518,"user_tz":-480,"elapsed":5,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import torch\n","from torchvision import transforms\n","\n","# Load image and extract its embedding.\n","input_image = Image.open('test_images/1_0.png').convert(\"RGB\")\n","convert_to_tensor = transforms.Compose([transforms.PILToTensor()])\n","input_tensor = convert_to_tensor(input_image)\n","input_batch = input_tensor.unsqueeze(0)\n","out = model(input_batch)[0]\n","# out = embedding_fn(input_batch)[0]\n","with torch.no_grad():\n","  embedding = torch.flatten(out).cpu().data.numpy()"],"metadata":{"id":"iVE_uRg5iuFS","executionInfo":{"status":"ok","timestamp":1662444367356,"user_tz":-480,"elapsed":840,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(output['state_dict'])\n","model.eval()\n","saved_model = torch.jit.script(model)\n","saved_model.save('saved_model.pt')\n","from zipfile import ZipFile\n","\n","with ZipFile('submission.zip','w') as zip:           \n","  zip.write('saved_model.pt', arcname='saved_model.pt')"],"metadata":{"id":"MX0Xres6RWJI","executionInfo":{"status":"ok","timestamp":1662444372175,"user_tz":-480,"elapsed":4820,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","import torch\n","from torchvision import transforms\n","\n","# Model loading.\n","model = torch.jit.load('saved_model.pt')\n","model.eval()\n","embedding_fn = model\n","\n","# Load image and extract its embedding.\n","input_image = Image.open('test_images/1_0.png').convert(\"RGB\")\n","convert_to_tensor = transforms.Compose([transforms.PILToTensor()])\n","input_tensor = convert_to_tensor(input_image)\n","input_batch = input_tensor.unsqueeze(0)\n","out = model(input_batch)[0]\n","# out = embedding_fn(input_batch)[0]\n","with torch.no_grad():\n","  embedding = torch.flatten(out).cpu().data.numpy()"],"metadata":{"id":"SG9N_7D8erbk","executionInfo":{"status":"ok","timestamp":1662444373469,"user_tz":-480,"elapsed":1299,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CfJHyOtLIocC","executionInfo":{"status":"ok","timestamp":1662444373470,"user_tz":-480,"elapsed":5,"user":{"displayName":"Tim Wu","userId":"07318600540774671561"}}},"execution_count":13,"outputs":[]}]}